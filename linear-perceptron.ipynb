{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Perceptron\n",
    "By Oliver Blasko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the regular expression `\\s+` for separator to indicate that separator is one or multiple spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./spine_data_ascii.txt\", sep=\"\\s+\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.841641</td>\n",
       "      <td>45.252792</td>\n",
       "      <td>80.111572</td>\n",
       "      <td>70.399308</td>\n",
       "      <td>61.446597</td>\n",
       "      <td>56.535051</td>\n",
       "      <td>79.938570</td>\n",
       "      <td>53.936748</td>\n",
       "      <td>73.635962</td>\n",
       "      <td>84.585607</td>\n",
       "      <td>...</td>\n",
       "      <td>69.297008</td>\n",
       "      <td>87.679087</td>\n",
       "      <td>65.007964</td>\n",
       "      <td>68.832021</td>\n",
       "      <td>74.094731</td>\n",
       "      <td>77.409333</td>\n",
       "      <td>39.056951</td>\n",
       "      <td>95.480229</td>\n",
       "      <td>49.782121</td>\n",
       "      <td>63.027817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.073991</td>\n",
       "      <td>8.693157</td>\n",
       "      <td>33.942432</td>\n",
       "      <td>13.469986</td>\n",
       "      <td>22.694968</td>\n",
       "      <td>14.377189</td>\n",
       "      <td>18.774071</td>\n",
       "      <td>20.721496</td>\n",
       "      <td>9.711318</td>\n",
       "      <td>30.361685</td>\n",
       "      <td>...</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>20.365613</td>\n",
       "      <td>27.602608</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>18.823727</td>\n",
       "      <td>29.396545</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>46.550053</td>\n",
       "      <td>6.466805</td>\n",
       "      <td>22.552586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.641233</td>\n",
       "      <td>41.583126</td>\n",
       "      <td>85.101608</td>\n",
       "      <td>61.200000</td>\n",
       "      <td>46.170347</td>\n",
       "      <td>44.991547</td>\n",
       "      <td>63.311835</td>\n",
       "      <td>29.220534</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>65.479486</td>\n",
       "      <td>...</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>93.822416</td>\n",
       "      <td>50.947519</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>76.032156</td>\n",
       "      <td>63.232302</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>39.609117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.767649</td>\n",
       "      <td>36.559635</td>\n",
       "      <td>46.169139</td>\n",
       "      <td>56.929322</td>\n",
       "      <td>38.751628</td>\n",
       "      <td>42.157862</td>\n",
       "      <td>61.164499</td>\n",
       "      <td>33.215251</td>\n",
       "      <td>63.924644</td>\n",
       "      <td>54.223922</td>\n",
       "      <td>...</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>67.313473</td>\n",
       "      <td>37.405357</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>55.271004</td>\n",
       "      <td>48.012788</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>48.930176</td>\n",
       "      <td>43.315316</td>\n",
       "      <td>40.475232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123.945240</td>\n",
       "      <td>118.545840</td>\n",
       "      <td>125.593620</td>\n",
       "      <td>102.337520</td>\n",
       "      <td>125.670720</td>\n",
       "      <td>101.723330</td>\n",
       "      <td>114.787110</td>\n",
       "      <td>114.365840</td>\n",
       "      <td>98.727930</td>\n",
       "      <td>108.010220</td>\n",
       "      <td>...</td>\n",
       "      <td>101.868500</td>\n",
       "      <td>120.944830</td>\n",
       "      <td>116.581110</td>\n",
       "      <td>105.985140</td>\n",
       "      <td>128.405730</td>\n",
       "      <td>118.450730</td>\n",
       "      <td>114.405430</td>\n",
       "      <td>96.683903</td>\n",
       "      <td>110.864780</td>\n",
       "      <td>98.672917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.199249</td>\n",
       "      <td>0.214750</td>\n",
       "      <td>100.292110</td>\n",
       "      <td>25.538429</td>\n",
       "      <td>-2.707879</td>\n",
       "      <td>25.773174</td>\n",
       "      <td>38.538741</td>\n",
       "      <td>-0.421010</td>\n",
       "      <td>26.975787</td>\n",
       "      <td>25.118478</td>\n",
       "      <td>...</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>76.730629</td>\n",
       "      <td>7.015978</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>73.388216</td>\n",
       "      <td>93.563737</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>77.283072</td>\n",
       "      <td>25.335647</td>\n",
       "      <td>-0.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1           2           3           4           5    \\\n",
       "0   33.841641   45.252792   80.111572   70.399308   61.446597   56.535051   \n",
       "1    5.073991    8.693157   33.942432   13.469986   22.694968   14.377189   \n",
       "2   36.641233   41.583126   85.101608   61.200000   46.170347   44.991547   \n",
       "3   28.767649   36.559635   46.169139   56.929322   38.751628   42.157862   \n",
       "4  123.945240  118.545840  125.593620  102.337520  125.670720  101.723330   \n",
       "5   -0.199249    0.214750  100.292110   25.538429   -2.707879   25.773174   \n",
       "6    0.000000    0.000000    1.000000    1.000000    0.000000    1.000000   \n",
       "\n",
       "          6           7          8           9      ...             300  \\\n",
       "0   79.938570   53.936748  73.635962   84.585607    ...       69.297008   \n",
       "1   18.774071   20.721496   9.711318   30.361685    ...       24.652878   \n",
       "2   63.311835   29.220534  63.000000   65.479486    ...       44.311238   \n",
       "3   61.164499   33.215251  63.924644   54.223922    ...       44.644130   \n",
       "4  114.787110  114.365840  98.727930  108.010220    ...      101.868500   \n",
       "5   38.538741   -0.421010  26.975787   25.118478    ...       11.211523   \n",
       "6    1.000000    0.000000   1.000000    1.000000    ...        1.000000   \n",
       "\n",
       "          301         302         303         304         305         306  \\\n",
       "0   87.679087   65.007964   68.832021   74.094731   77.409333   39.056951   \n",
       "1   20.365613   27.602608   22.218482   18.823727   29.396545   10.060991   \n",
       "2   93.822416   50.947519   50.092194   76.032156   63.232302   25.015378   \n",
       "3   67.313473   37.405357   46.613539   55.271004   48.012788   28.995960   \n",
       "4  120.944830  116.581110  105.985140  128.405730  118.450730  114.405430   \n",
       "5   76.730629    7.015978   -3.530317   73.388216   93.563737    4.564259   \n",
       "6    1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         307         308        309  \n",
       "0  95.480229   49.782121  63.027817  \n",
       "1  46.550053    6.466805  22.552586  \n",
       "2  59.000000   53.000000  39.609117  \n",
       "3  48.930176   43.315316  40.475232  \n",
       "4  96.683903  110.864780  98.672917  \n",
       "5  77.283072   25.335647  -0.254400  \n",
       "6   1.000000    1.000000   1.000000  \n",
       "\n",
       "[7 rows x 310 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframe seems to be \"upside down\", we need to transpose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.841641</td>\n",
       "      <td>5.073991</td>\n",
       "      <td>36.641233</td>\n",
       "      <td>28.767649</td>\n",
       "      <td>123.94524</td>\n",
       "      <td>-0.199249</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.252792</td>\n",
       "      <td>8.693157</td>\n",
       "      <td>41.583126</td>\n",
       "      <td>36.559635</td>\n",
       "      <td>118.54584</td>\n",
       "      <td>0.214750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.111572</td>\n",
       "      <td>33.942432</td>\n",
       "      <td>85.101608</td>\n",
       "      <td>46.169139</td>\n",
       "      <td>125.59362</td>\n",
       "      <td>100.292110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.399308</td>\n",
       "      <td>13.469986</td>\n",
       "      <td>61.200000</td>\n",
       "      <td>56.929322</td>\n",
       "      <td>102.33752</td>\n",
       "      <td>25.538429</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.446597</td>\n",
       "      <td>22.694968</td>\n",
       "      <td>46.170347</td>\n",
       "      <td>38.751628</td>\n",
       "      <td>125.67072</td>\n",
       "      <td>-2.707879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.535051</td>\n",
       "      <td>14.377189</td>\n",
       "      <td>44.991547</td>\n",
       "      <td>42.157862</td>\n",
       "      <td>101.72333</td>\n",
       "      <td>25.773174</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79.938570</td>\n",
       "      <td>18.774071</td>\n",
       "      <td>63.311835</td>\n",
       "      <td>61.164499</td>\n",
       "      <td>114.78711</td>\n",
       "      <td>38.538741</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53.936748</td>\n",
       "      <td>20.721496</td>\n",
       "      <td>29.220534</td>\n",
       "      <td>33.215251</td>\n",
       "      <td>114.36584</td>\n",
       "      <td>-0.421010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73.635962</td>\n",
       "      <td>9.711318</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.924644</td>\n",
       "      <td>98.72793</td>\n",
       "      <td>26.975787</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84.585607</td>\n",
       "      <td>30.361685</td>\n",
       "      <td>65.479486</td>\n",
       "      <td>54.223922</td>\n",
       "      <td>108.01022</td>\n",
       "      <td>25.118478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4           5    6\n",
       "0  33.841641   5.073991  36.641233  28.767649  123.94524   -0.199249  0.0\n",
       "1  45.252792   8.693157  41.583126  36.559635  118.54584    0.214750  0.0\n",
       "2  80.111572  33.942432  85.101608  46.169139  125.59362  100.292110  1.0\n",
       "3  70.399308  13.469986  61.200000  56.929322  102.33752   25.538429  1.0\n",
       "4  61.446597  22.694968  46.170347  38.751628  125.67072   -2.707879  0.0\n",
       "5  56.535051  14.377189  44.991547  42.157862  101.72333   25.773174  1.0\n",
       "6  79.938570  18.774071  63.311835  61.164499  114.78711   38.538741  1.0\n",
       "7  53.936748  20.721496  29.220534  33.215251  114.36584   -0.421010  0.0\n",
       "8  73.635962   9.711318  63.000000  63.924644   98.72793   26.975787  1.0\n",
       "9  84.585607  30.361685  65.479486  54.223922  108.01022   25.118478  1.0"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 7)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have 310 rows -- patients, and 7 columns -- 6 spine measurements and binary output variable where:\n",
    "- 1 stands for patients with abnormal spines\n",
    "- 0 stands for patients with normal spines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearPerceptron:\n",
    "    #constructor\n",
    "    def __init__(self, df, input_vars, target_vars, bias, weight_initialization):\n",
    "        #dataframe\n",
    "        self.data = df\n",
    "        #indexes of input variables\n",
    "        self.input_vars = input_vars\n",
    "        #index of target -- output variable\n",
    "        self.target_vars = target_vars\n",
    "        #dictionary of weights\n",
    "        self.weights = {}\n",
    "        self.bias = bias\n",
    "        #type of initialization\n",
    "        self.weight_initialization = weight_initialization\n",
    "        #initialize weights\n",
    "        self.init()\n",
    "        #splits the data into training and testing set\n",
    "        self.splitData()\n",
    "        \n",
    "    #initializes starting weights\n",
    "    def init(self):\n",
    "        if( self.weight_initialization == \"default\" ):\n",
    "            for index in self.input_vars:\n",
    "                self.weights[index] = 0\n",
    "        elif( self.weight_initialization == \"random\"):\n",
    "            for index in self.input_vars:\n",
    "                self.weights[index] = random.uniform(-1, 1)\n",
    "                \n",
    "    #print current weights\n",
    "    def printWeights(self):\n",
    "        for key, value in self.weights.items():\n",
    "            print( \"w_\" + str(key) + \" = \" + str(value))\n",
    "    \n",
    "    #returns output of the perceptron\n",
    "    def predict(self, row):\n",
    "        sum_ = 0\n",
    "        #iterate over all input variables\n",
    "        for col_index in self.input_vars:\n",
    "            #sum = sum + x_i * w_i \n",
    "            sum_ += row[col_index]*self.weights[col_index]\n",
    "        #sum = sum + bias(b)\n",
    "        sum_ += self.bias\n",
    "        #sign function\n",
    "        return self.activate(sum_)\n",
    "    \n",
    "    #sign function, but returns 0 instead of -1 if less than 0\n",
    "    def activate(self, x):\n",
    "        if( x > 0 ):\n",
    "            return 1;\n",
    "        return 0;\n",
    "    \n",
    "    def updateWeights(self, row, error):\n",
    "        #iterate over all weights\n",
    "        for index in self.input_vars:\n",
    "            #w_i = w_i + (t-y)*x_i\n",
    "            self.weights[index] += error*row[index]\n",
    "        \n",
    "    def train(self):\n",
    "        #iterate over every data_point\n",
    "        for index, row in self.train_data.iterrows():\n",
    "            #output of perceptron\n",
    "            prediction = self.predict( row )\n",
    "            #actual target value(t) - output of the perceptron(y)\n",
    "            error = row[self.target_vars] - prediction\n",
    "            #b = b + ( target value(t) - output of the perceptron(y) )\n",
    "            self.bias += error\n",
    "            #update weights by adding (t-y)*x\n",
    "            self.updateWeights( row, error )\n",
    "            \n",
    "    #splits data into training and testing set\n",
    "    def splitData(self):\n",
    "        #index of 75%\n",
    "        threshold = int(np.floor((self.data.shape[0]/100)*75))\n",
    "        self.train_data = pd.DataFrame(self.data.iloc[0:threshold,:])\n",
    "        self.test_data = pd.DataFrame(self.data.iloc[threshold:,:])\n",
    "    \n",
    "    #feeding the perceptron with testing data and computes accuracy\n",
    "    #ACCURACY = (correct_prediction/total_predictions)*100\n",
    "    def evaluate(self):\n",
    "        correct_prediction = 0\n",
    "        for index, row in self.test_data.iterrows():\n",
    "               prediction = self.predict( row )\n",
    "               if( prediction == row[self.target_vars] ):\n",
    "                   correct_prediction+=1\n",
    "        accuracy = (correct_prediction/self.test_data.shape[0])*100\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing \n",
    "\n",
    "Let's test our LinearPerceptron class.\n",
    "\n",
    "- Firstly LinearPerceptron with defualt( =0 ) init weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights:\n",
      "w_0 = 102.28249800000003\n",
      "w_1 = 218.88135369000003\n",
      "w_2 = 31.274696999999996\n",
      "w_3 = -116.59885199999998\n",
      "w_4 = -7.6972439999999125\n",
      "w_5 = 609.3911698000002\n",
      "\n",
      "Final bias is: 2.0\n",
      "\n",
      "Accuracy of the linear perceptron 69.23076923076923\n"
     ]
    }
   ],
   "source": [
    "LP = LinearPerceptron(data, [0,1,2,3,4,5], 6, 0, \"default\")\n",
    "LP.train()\n",
    "print(\"Final Weights:\")\n",
    "LP.printWeights()\n",
    "\n",
    "print()\n",
    "print(\"Final bias is: \" + str(LP.bias))\n",
    "print()\n",
    "print(\"Accuracy of the linear perceptron \" + str(LP.evaluate()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Secondly LinearPerceptron with random( range(-1,1) ) init weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights:\n",
      "w_0 = 112.6340186458844\n",
      "w_1 = 214.80493275709682\n",
      "w_2 = -19.835330777032155\n",
      "w_3 = -104.04755944628823\n",
      "w_4 = -50.72803036343562\n",
      "w_5 = 553.1241589976183\n",
      "\n",
      "Final bias is: 2.0\n",
      "\n",
      "Accuracy of the linear perceptron 71.7948717948718\n"
     ]
    }
   ],
   "source": [
    "LP2 = LinearPerceptron(data, [0,1,2,3,4,5], 6, 0, \"random\")\n",
    "LP2.train()\n",
    "print(\"Final Weights:\")\n",
    "LP2.printWeights()\n",
    "\n",
    "print()\n",
    "print(\"Final bias is: \" + str(LP2.bias))\n",
    "print()\n",
    "print(\"Accuracy of the linear perceptron \" + str(LP2.evaluate()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Our linear perceptrons aren't very accurate. We could probably improve our models by splitting the data into training and testing set randomly or training them on multiple epochs. Initializing initial weights randomly rather than default assignment to 0 improved our perceptron by ~2%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
